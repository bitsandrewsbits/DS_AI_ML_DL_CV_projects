{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463bd9f5-1618-40cb-b185-b865419490d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    accuracy_score, ConfusionMatrixDisplay\n",
    ")\n",
    "import mlflow as mlf\n",
    "from mlflow.sklearn import log_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d35f2-72b4-4059-bacd-4a0eb696580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: think, how to add validation flag for further extracting from mlflow experiment class\n",
    "# in order to change name of experiment run.\n",
    "class Dataset_Analyzer:\n",
    "    def __init__(self, dataset_url: str):\n",
    "        self.CSV_dataset_URL = dataset_url\n",
    "        self.CSV_dataset = self.get_dataset_in_CSV_from_URL(self.CSV_dataset_URL)\n",
    "        self.dataset_column_names = self.get_dataset_columns_names()\n",
    "        self.dataset_columns_types = dict(self.CSV_dataset.dtypes)\n",
    "        self.dataset_columns_with_missing_values = []\n",
    "        self.missing_values_columns_with_int_float_dtypes = []\n",
    "        \n",
    "        self.target_y_columns = ['Survived']\n",
    "        self.features_set_X = pd.DataFrame()\n",
    "        self.target_set_y = pd.DataFrame()\n",
    "        self.train_set_X = pd.DataFrame()\n",
    "        self.train_set_y = np.array\n",
    "        self.test_set_X = pd.DataFrame()\n",
    "        self.test_set_y = np.array\n",
    "        self.target_y_classes_names = ['Not Survived', 'Survived']\n",
    "    \n",
    "        self.ML_classifiers_model = {'random_forest': RandomForestClassifier} # in the future - maybe I add new models\n",
    "        self.selected_model_name_for_experiment = 'random_forest'\n",
    "        self.model_for_experiment = object\n",
    "        self.prediction_of_target_y = []\n",
    "        self.confusion_matrix = []\n",
    "        self.confusion_matrix_figure = object\n",
    "        self.classification_report = {}\n",
    "        self.model_accuracy = 0.0\n",
    "    \n",
    "    def main(self):\n",
    "        self.make_data_preparation_for_training()\n",
    "        print('Training ML model.')\n",
    "        self.init_classifier_model_for_experiment(self.selected_model_name_for_experiment)\n",
    "        self.train_classifier_model()\n",
    "        print('Make prediction of target y values from test set X')\n",
    "        self.make_prediction_on_test_dataset()\n",
    "        print('Model Evaluation:')\n",
    "        self.evaluate_quality_of_ML_model()\n",
    "        self.define_confusion_matrix_figure()\n",
    "    \n",
    "    def make_data_preparation_for_training(self):\n",
    "        self.show_dataset()\n",
    "        self.show_dataset_columns()\n",
    "        self.remove_all_string_type_columns_from_dataset()\n",
    "        self.update_dataset_columns_names()\n",
    "        self.update_dataset_columns_types()\n",
    "        self.define_columns_with_missing_values_from_dataset()\n",
    "        self.define_int_float_dtype_missing_value_columns()\n",
    "        self.replace_columns_NaN_values_with_mean_values()\n",
    "        print('After data cleaning and replacing:')\n",
    "        self.show_dataset()\n",
    "        print('=' * 40)\n",
    "        self.define_features_set_X()\n",
    "        self.define_target_set_y()\n",
    "        self.features_max_abs_normalization()\n",
    "        print('Features set X after max abs normalization:')\n",
    "        self.show_features_set_X()\n",
    "        print('=' * 40)\n",
    "        print('Splitting dataset for train and test stages.')\n",
    "        self.split_dataset_into_train_test_parts()\n",
    "        print('=' * 40)\n",
    "    \n",
    "    def show_dataset(self):\n",
    "        print(self.CSV_dataset)\n",
    "    \n",
    "    def get_dataset_columns_names(self):\n",
    "        return self.CSV_dataset.columns\n",
    "    \n",
    "    def update_dataset_columns_names(self):\n",
    "        self.dataset_column_names = self.get_dataset_columns_names()\n",
    "    \n",
    "    def update_dataset_columns_types(self):\n",
    "        self.dataset_columns_types = dict(self.CSV_dataset.dtypes)\n",
    "    \n",
    "    def show_dataset_columns_types(self):\n",
    "        print(self.dataset_columns_types)\n",
    "    \n",
    "    def show_dataset_columns(self):\n",
    "        print(self.dataset_column_names)\n",
    "    \n",
    "    def get_dataset_in_CSV_from_URL(self, url: str):\n",
    "        return pd.read_csv(url)\n",
    "    \n",
    "    def remove_all_string_type_columns_from_dataset(self):\n",
    "        for dataset_column_name in self.dataset_columns_types:\n",
    "            if self.dataset_columns_types[dataset_column_name] == object:\n",
    "                self.CSV_dataset = self.CSV_dataset.drop(dataset_column_name, axis = 1)\n",
    "        return True\n",
    "    \n",
    "    def define_columns_with_missing_values_from_dataset(self):\n",
    "        missing_values_by_bool_mapping_of_dataset = self.CSV_dataset.isna()\n",
    "    \n",
    "        for dataset_column in self.dataset_column_names:\n",
    "            column_values = missing_values_by_bool_mapping_of_dataset[dataset_column].values\n",
    "            if True in column_values:\n",
    "                self.dataset_columns_with_missing_values.append(dataset_column)\n",
    "                print(f'Missing values column - {dataset_column}!')\n",
    "        return True\n",
    "    \n",
    "    def define_int_float_dtype_missing_value_columns(self):\n",
    "        for missing_value_column in self.dataset_columns_with_missing_values:\n",
    "            if self.dataset_columns_types[missing_value_column] != object:\n",
    "                self.missing_values_columns_with_int_float_dtypes.append(missing_value_column)\n",
    "        return True\n",
    "    \n",
    "    def replace_columns_NaN_values_with_mean_values(self):\n",
    "        for int_float_column in self.missing_values_columns_with_int_float_dtypes:\n",
    "            column_mean_value = self.CSV_dataset[int_float_column].mean(skipna = True)\n",
    "            self.CSV_dataset[int_float_column] = self.CSV_dataset[int_float_column].replace(\n",
    "                to_replace = np.nan, value = column_mean_value\n",
    "            )\n",
    "        return True\n",
    "    \n",
    "    def define_features_set_X(self):\n",
    "        for target_y_column in self.target_y_columns:\n",
    "            self.features_set_X = self.CSV_dataset.drop(target_y_column, axis = 1)\n",
    "        return True\n",
    "    \n",
    "    def show_features_set_X(self):\n",
    "        print(self.features_set_X)\n",
    "    \n",
    "    def define_target_set_y(self):\n",
    "        self.target_set_y = self.CSV_dataset[self.target_y_columns]\n",
    "        return True\n",
    "    \n",
    "    def split_dataset_into_train_test_parts(self):\n",
    "        self.train_set_X, self.test_set_X, \\\n",
    "        self.train_set_y, self.test_set_y = train_test_split(\n",
    "            self.features_set_X, self.target_set_y, test_size = 0.2, random_state = 42\n",
    "            )\n",
    "        self.train_set_y = self.train_set_y.values.reshape(-1)\n",
    "        return True\n",
    "    \n",
    "    def features_max_abs_normalization(self):\n",
    "        features_column_names = self.features_set_X.columns\n",
    "        for features_column in features_column_names:\n",
    "            max_abs_column_value = self.features_set_X[features_column].abs().max()\n",
    "            self.features_set_X[features_column] = self.features_set_X[features_column] / max_abs_column_value\n",
    "        return True\n",
    "    \n",
    "    def init_classifier_model_for_experiment(self, model_name: str):\n",
    "        self.model_for_experiment = self.ML_classifiers_model[model_name]()\n",
    "    \n",
    "    def train_classifier_model(self):\n",
    "        self.model_for_experiment.fit(self.train_set_X, self.train_set_y)\n",
    "    \n",
    "    def make_prediction_on_test_dataset(self):\n",
    "        self.prediction_of_target_y = self.model_for_experiment.predict(self.test_set_X)\n",
    "    \n",
    "    # TODO: change output format for mlflow detecting and logging into Run.\n",
    "    def evaluate_quality_of_ML_model(self):\n",
    "        self.define_confusion_matrix()\n",
    "        self.define_classification_report()\n",
    "        self.define_model_accuracy()\n",
    "    \n",
    "    def define_confusion_matrix(self):\n",
    "        self.confusion_matrix = confusion_matrix(self.test_set_y, self.prediction_of_target_y)\n",
    "\n",
    "    def define_model_accuracy(self):\n",
    "        self.model_accuracy = accuracy_score(self.test_set_y, self.prediction_of_target_y)\n",
    "\n",
    "    def define_confusion_matrix_figure(self):\n",
    "        confusion_matrix_display_obj = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = self.confusion_matrix,\n",
    "            display_labels = self.model_for_experiment.classes_\n",
    "        )\n",
    "        self.confusion_matrix_figure = confusion_matrix_display_obj.plot().figure_\n",
    "\n",
    "    def define_classification_report(self):\n",
    "        self.classification_report = classification_report(\n",
    "            self.test_set_y, self.prediction_of_target_y,\n",
    "            target_names = self.target_y_classes_names,\n",
    "            output_dict = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af610e2c-8bd2-4015-a3f9-0114a066ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFlow experiment environment initiating and running\n",
    "# This notebook only for testing as API for main classifier program.\n",
    "class MLFlow_Experiment_Runner:\n",
    "    def __init__(self, classifier_model_name: str):\n",
    "        self.classifier_model_name = classifier_model_name\n",
    "        self.experiment_name = self.get_experiment_name()\n",
    "        self.active_experiment = object\n",
    "        self.current_run_name = ''\n",
    "        self.max_experiment_runs = 10\n",
    "        self.tracking_server_IP = os.getenv('MLFLOW_IP')\n",
    "        self.tracking_server_port = 5000\n",
    "        self.tracking_server_URI = f\"http://{self.tracking_server_IP}:{self.tracking_server_port}\"\n",
    "\n",
    "    def main(self, target_classifier_object):\n",
    "        self.set_mlflow_server_URI()\n",
    "        if self.experiment_exist():\n",
    "            print(f'[INFO] Experiment - {self.experiment_name} - active!')\n",
    "            self.set_experiment_as_active()\n",
    "        else:\n",
    "            print(f'[INFO] Experiment - {self.experiment_name} does not exist!')\n",
    "            self.create_new_experiment()\n",
    "        runs_name_endtime_pairs = self.get_experiment_runs_name_endtime_pairs()\n",
    "        runs_name_endtime_pairs.sort(key = lambda run: run['end_time'])\n",
    "        if self.experiment_exceed_max_runs(runs_name_endtime_pairs):\n",
    "            print(f\"[INFO] Experiment has more than {self.max_experiment_runs} runs. Deleting old runs...\")\n",
    "            self.delete_old_time_experiment_runs(runs_name_endtime_pairs)\n",
    "            \n",
    "        self.current_run_name = self.get_current_run_name()\n",
    "        with mlf.start_run(run_name = self.current_run_name):\n",
    "            print(\"[INFO] Start classifier experiment...\")\n",
    "            mlf.sklearn.autolog(disable = True)\n",
    "            target_classifier_object.main()\n",
    "            mlf.log_metric('model_accuracy', target_classifier_object.model_accuracy)\n",
    "            mlf.log_figure(\n",
    "                target_classifier_object.confusion_matrix_figure,\n",
    "                artifact_file = 'confusion_matrix.png'\n",
    "            )\n",
    "            mlf.log_dict(\n",
    "                dictionary = target_classifier_object.classification_report,\n",
    "                artifact_file = 'classification_report.json'\n",
    "            )\n",
    "            log_model(\n",
    "                sk_model = target_classifier_object.model_for_experiment,\n",
    "                name = self.classifier_model_name\n",
    "            )\n",
    "\n",
    "    def set_mlflow_server_URI(self):\n",
    "        print('[INFO] Setting Tracking Server URI...')\n",
    "        mlf.set_tracking_uri(self.tracking_server_URI)\n",
    "    \n",
    "    def get_experiment_name(self):\n",
    "        return f\"{self.classifier_model_name}_classifier\"\n",
    "    \n",
    "    def experiment_exist(self):\n",
    "        if mlf.get_experiment_by_name(self.experiment_name):\n",
    "            print(f'[INFO] Experiment {self.experiment_name} already exist!')\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def create_new_experiment(self):\n",
    "        print(f'[INFO] Creating experiment - {self.experiment_name}...')\n",
    "        mlf.create_experiment(self.experiment_name)\n",
    "    \n",
    "    def set_experiment_as_active(self):\n",
    "        return mlf.set_experiment(self.experiment_name)\n",
    "\n",
    "    def get_current_run_name(self):\n",
    "        runs = self.get_experiment_runs_name_endtime_pairs()\n",
    "        current_run_number = len(runs) + 1\n",
    "        return f\"train_test_{current_run_number}\"\n",
    "\n",
    "    def delete_old_time_experiment_runs(self, runs: list):\n",
    "        target_runs_for_deleting = self.get_target_runs_for_deleting(runs)\n",
    "        for run in target_runs_for_deleting:\n",
    "            run_ID = run['run_ID']\n",
    "            mlf.delete_run(run_ID)\n",
    "            print(f\"[INFO] Deleted Run with ID: {run_ID}\")\n",
    "        return True\n",
    "\n",
    "    def get_target_runs_for_deleting(self, sorted_runs_by_time: list):\n",
    "        return sorted_runs_by_time[:self.max_experiment_runs]\n",
    "    \n",
    "    def experiment_exceed_max_runs(self, runs: list):\n",
    "        runs_amount = len(runs)\n",
    "        if runs_amount <= self.max_experiment_runs:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "            \n",
    "    def get_experiment_runs_name_endtime_pairs(self) -> list[dict]:\n",
    "        runs = mlf.search_runs(\n",
    "            experiment_names = [self.experiment_name],\n",
    "            output_format = 'list'\n",
    "        )\n",
    "        runs_name_endtime_pairs = []\n",
    "        for run in runs:\n",
    "            pair = {'run_ID': run.info.run_id, 'end_time': run.info.end_time}\n",
    "            runs_name_endtime_pairs.append(pair)\n",
    "        return runs_name_endtime_pairs\n",
    "\t\n",
    "dataset_analyzer = Dataset_Analyzer(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "mlflow_experiment = MLFlow_Experiment_Runner('random_forest')\n",
    "mlflow_experiment.main(dataset_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea7ea6-3841-43d7-984f-8b7bed339ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
