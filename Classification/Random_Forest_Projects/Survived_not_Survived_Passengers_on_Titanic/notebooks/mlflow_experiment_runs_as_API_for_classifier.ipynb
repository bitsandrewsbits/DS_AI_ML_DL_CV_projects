{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d35f2-72b4-4059-bacd-4a0eb696580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# TODO: think, how to add validation flag for further extracting from mlflow experiment class\n",
    "# in order to change name of experiment run.\n",
    "class Dataset_Analyzer:\n",
    "\tdef __init__(self, dataset_url: str):\n",
    "\t\tself.CSV_dataset_URL = dataset_url\n",
    "\t\tself.CSV_dataset = self.get_dataset_in_CSV_from_URL(self.CSV_dataset_URL)\n",
    "\t\tself.dataset_column_names = self.get_dataset_columns_names()\n",
    "\t\tself.dataset_columns_types = dict(self.CSV_dataset.dtypes)\n",
    "\t\tself.dataset_columns_with_missing_values = []\n",
    "\t\tself.missing_values_columns_with_int_float_dtypes = []\n",
    "\t\t\n",
    "\t\tself.target_y_columns = ['Survived']\n",
    "\t\tself.features_set_X = pd.DataFrame()\n",
    "\t\tself.target_set_y = pd.DataFrame()\n",
    "\n",
    "\t\tself.train_set_X = pd.DataFrame()\n",
    "\t\tself.train_set_y = np.array\n",
    "\t\tself.test_set_X = pd.DataFrame()\n",
    "\t\tself.test_set_y = np.array\n",
    "\n",
    "\t\tself.ML_classifiers_model = {'random_forest': RandomForestClassifier} # in the future - maybe I add new models\n",
    "\t\tself.selected_model_name_for_experiment = 'random_forest'\n",
    "\t\tself.model_for_experiment = object\n",
    "\t\tself.prediction_of_target_y = []\n",
    "\n",
    "\tdef main(self):\n",
    "\t\tself.make_data_preparation_for_training()\n",
    "\t\tprint('Training ML model.')\n",
    "\t\tself.init_classifier_model_for_experiment(self.selected_model_name_for_experiment)\n",
    "\t\tdataset_analyzer.train_classifier_model()\n",
    "\t\tprint('Make prediction of target y values from test set X')\n",
    "\t\tdataset_analyzer.make_prediction_on_test_dataset()\n",
    "\t\tprint('Model Evaluation:')\n",
    "\t\tdataset_analyzer.evaluate_quality_of_ML_model()\n",
    "\n",
    "\tdef make_data_preparation_for_training(self):\n",
    "\t\tself.show_dataset()\n",
    "\t\tself.show_dataset_columns()\n",
    "\t\tself.remove_all_string_type_columns_from_dataset()\n",
    "\t\tself.update_dataset_columns_names()\n",
    "\t\tself.update_dataset_columns_types()\n",
    "\t\tself.define_columns_with_missing_values_from_dataset()\n",
    "\t\tself.define_int_float_dtype_missing_value_columns()\n",
    "\t\tself.replace_columns_NaN_values_with_mean_values()\n",
    "\t\tprint('After data cleaning and replacing:')\n",
    "\t\tself.show_dataset()\n",
    "\t\tprint('=' * 40)\n",
    "\t\tself.define_features_set_X()\n",
    "\t\tself.define_target_set_y()\n",
    "\t\tself.features_max_abs_normalization()\n",
    "\t\tprint('Features set X after max abs normalization:')\n",
    "\t\tself.show_features_set_X()\n",
    "\t\tprint('=' * 40)\n",
    "\t\tprint('Splitting dataset for train and test stages.')\n",
    "\t\tself.split_dataset_into_train_test_parts()\n",
    "\t\tprint('=' * 40)\n",
    "\n",
    "\tdef show_dataset(self):\n",
    "\t\tprint(self.CSV_dataset)\n",
    "\n",
    "\tdef get_dataset_columns_names(self):\n",
    "\t\treturn self.CSV_dataset.columns\n",
    "\n",
    "\tdef update_dataset_columns_names(self):\n",
    "\t\tself.dataset_column_names = self.get_dataset_columns_names()\n",
    "\n",
    "\tdef update_dataset_columns_types(self):\n",
    "\t\tself.dataset_columns_types = dict(self.CSV_dataset.dtypes)\n",
    "\n",
    "\tdef show_dataset_columns_types(self):\n",
    "\t\tprint(self.dataset_columns_types)\n",
    "\n",
    "\tdef show_dataset_columns(self):\n",
    "\t\tprint(self.dataset_column_names)\n",
    "\n",
    "\tdef get_dataset_in_CSV_from_URL(self, url: str):\n",
    "\t\treturn pd.read_csv(url)\n",
    "\n",
    "\tdef remove_all_string_type_columns_from_dataset(self):\n",
    "\t\tfor dataset_column_name in self.dataset_columns_types:\n",
    "\t\t\tif self.dataset_columns_types[dataset_column_name] == object:\n",
    "\t\t\t\tself.CSV_dataset = self.CSV_dataset.drop(dataset_column_name, axis = 1)\n",
    "\t\treturn True\n",
    "\n",
    "\tdef define_columns_with_missing_values_from_dataset(self):\n",
    "\t\tmissing_values_by_bool_mapping_of_dataset = self.CSV_dataset.isna()\n",
    "\n",
    "\t\tfor dataset_column in self.dataset_column_names:\n",
    "\t\t\tcolumn_values = missing_values_by_bool_mapping_of_dataset[dataset_column].values\n",
    "\t\t\tif True in column_values:\n",
    "\t\t\t\tself.dataset_columns_with_missing_values.append(dataset_column)\n",
    "\t\t\t\tprint(f'Missing values column - {dataset_column}!')\n",
    "\t\treturn True\n",
    "\n",
    "\tdef define_int_float_dtype_missing_value_columns(self):\n",
    "\t\tfor missing_value_column in self.dataset_columns_with_missing_values:\n",
    "\t\t\tif self.dataset_columns_types[missing_value_column] != object:\n",
    "\t\t\t\tself.missing_values_columns_with_int_float_dtypes.append(missing_value_column)\n",
    "\t\treturn True\n",
    "\n",
    "\tdef replace_columns_NaN_values_with_mean_values(self):\n",
    "\t\tfor int_float_column in self.missing_values_columns_with_int_float_dtypes:\n",
    "\t\t\tcolumn_mean_value = self.CSV_dataset[int_float_column].mean(skipna = True)\n",
    "\t\t\tself.CSV_dataset[int_float_column] = self.CSV_dataset[int_float_column].replace(\n",
    "\t\t\t\tto_replace = np.nan, value = column_mean_value\n",
    "\t\t\t)\n",
    "\t\treturn True\n",
    "\n",
    "\tdef define_features_set_X(self):\n",
    "\t\tfor target_y_column in self.target_y_columns:\n",
    "\t\t\tself.features_set_X = self.CSV_dataset.drop(target_y_column, axis = 1)\n",
    "\t\treturn True\n",
    "\n",
    "\tdef show_features_set_X(self):\n",
    "\t\tprint(self.features_set_X)\n",
    "\n",
    "\tdef define_target_set_y(self):\n",
    "\t\tself.target_set_y = self.CSV_dataset[self.target_y_columns]\n",
    "\t\treturn True\n",
    "\n",
    "\tdef split_dataset_into_train_test_parts(self):\n",
    "\t\tself.train_set_X, self.test_set_X, \\\n",
    "\t\tself.train_set_y, self.test_set_y = train_test_split(\n",
    "\t\t\tself.features_set_X, self.target_set_y, test_size = 0.2, random_state = 42\n",
    "\t\t\t)\n",
    "\t\tself.train_set_y = self.train_set_y.values.reshape(-1)\n",
    "\t\treturn True\n",
    "\n",
    "\tdef features_max_abs_normalization(self):\n",
    "\t\tfeatures_column_names = self.features_set_X.columns\n",
    "\t\tfor features_column in features_column_names:\n",
    "\t\t\tmax_abs_column_value = self.features_set_X[features_column].abs().max()\n",
    "\t\t\tself.features_set_X[features_column] = self.features_set_X[features_column] / max_abs_column_value\n",
    "\t\treturn True\n",
    "\n",
    "\tdef init_classifier_model_for_experiment(self, model_name: str):\n",
    "\t\tself.model_for_experiment = self.ML_classifiers_model[model_name]()\n",
    "\n",
    "\tdef train_classifier_model(self):\n",
    "\t\tself.model_for_experiment.fit(self.train_set_X, self.train_set_y)\n",
    "\n",
    "\tdef make_prediction_on_test_dataset(self):\n",
    "\t\tself.prediction_of_target_y = self.model_for_experiment.predict(self.test_set_X)\n",
    "\n",
    "    # TODO: change output format for mlflow detecting and logging into Run.\n",
    "\tdef evaluate_quality_of_ML_model(self):\n",
    "\t\tprint('Confusion matrix:')\n",
    "\t\tprint(confusion_matrix(self.test_set_y, self.prediction_of_target_y))\n",
    "\t\tprint('\\nClassification Report:')\n",
    "\t\tprint(classification_report(self.test_set_y, self.prediction_of_target_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af610e2c-8bd2-4015-a3f9-0114a066ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFlow experiment environment initiating and running\n",
    "# This notebook only for testing as API for main classifier program.\n",
    "import mlflow as mlf\n",
    "import os\n",
    "\n",
    "class MLFlow_Experiment_Runner:\n",
    "    def __init__(self, classifier_model_name: str):\n",
    "        self.classifier_model_name = classifier_model_name\n",
    "        self.experiment_name = self.get_experiment_name()\n",
    "        self.active_experiment = object\n",
    "        self.current_run_name = ''\n",
    "        self.max_experiment_runs = 10\n",
    "        self.tracking_server_IP = os.getenv('MLFLOW_IP')\n",
    "        self.tracking_server_port = 5000\n",
    "        self.tracking_server_URI = f\"http://{self.tracking_server_IP}:{self.tracking_server_port}\"\n",
    "\n",
    "    def main(self, target_classifier_program):\n",
    "        self.set_mlflow_server_URI()\n",
    "        if self.experiment_exist():\n",
    "            print(f'[INFO] Experiment - {self.experiment_name} - active!')\n",
    "            self.set_experiment_as_active()\n",
    "        else:\n",
    "            print(f'[INFO] Experiment - {self.experiment_name} does not exist!')\n",
    "            self.create_new_experiment()\n",
    "        runs_name_endtime_pairs = self.get_experiment_runs_name_endtime_pairs()\n",
    "        runs_name_endtime_pairs.sort(key = lambda run: run['end_time'])\n",
    "        if self.experiment_exceed_max_runs(runs_name_endtime_pairs):\n",
    "            print(f\"[INFO] Experiment has more than {self.max_experiment_runs} runs. Deleting old runs...\")\n",
    "            self.delete_old_time_experiment_runs(runs_name_endtime_pairs)\n",
    "            \n",
    "        self.current_run_name = self.get_current_run_name()\n",
    "        with mlf.start_run(run_name = self.current_run_name):\n",
    "            print(\"[INFO] Start classifier experiment...\")\n",
    "            mlf.sklearn.autolog()\n",
    "            target_classifier_program()\n",
    "    \n",
    "    def set_mlflow_server_URI(self):\n",
    "        print('[INFO] Setting Tracking Server URI...')\n",
    "        mlf.set_tracking_uri(self.tracking_server_URI)\n",
    "    \n",
    "    def get_experiment_name(self):\n",
    "        return f\"{self.classifier_model_name}_classifier\"\n",
    "    \n",
    "    def experiment_exist(self):\n",
    "        if mlf.get_experiment_by_name(self.experiment_name):\n",
    "            print(f'[INFO] Experiment {self.experiment_name} already exist!')\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def create_new_experiment(self):\n",
    "        print(f'[INFO] Creating experiment - {self.experiment_name}...')\n",
    "        mlf.create_experiment(self.experiment_name)\n",
    "    \n",
    "    def set_experiment_as_active(self):\n",
    "        return mlf.set_experiment(self.experiment_name)\n",
    "\n",
    "    def get_current_run_name(self):\n",
    "        runs = self.get_experiment_runs_name_endtime_pairs()\n",
    "        current_run_number = len(runs) + 1\n",
    "        return f\"train_test_{current_run_number}\"\n",
    "\n",
    "    def delete_old_time_experiment_runs(self, runs: list):\n",
    "        target_runs_for_deleting = self.get_target_runs_for_deleting(runs)\n",
    "        for run in target_runs_for_deleting:\n",
    "            run_ID = run['run_ID']\n",
    "            mlf.delete_run(run_ID)\n",
    "            print(f\"[INFO] Deleted Run with ID: {run_ID}\")\n",
    "        return True\n",
    "\n",
    "    def get_target_runs_for_deleting(self, sorted_runs_by_time: list):\n",
    "        return sorted_runs_by_time[:self.max_experiment_runs]\n",
    "    \n",
    "    def experiment_exceed_max_runs(self, runs: list):\n",
    "        runs_amount = len(runs)\n",
    "        if runs_amount <= self.max_experiment_runs:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "            \n",
    "    def get_experiment_runs_name_endtime_pairs(self) -> list[dict]:\n",
    "        runs = mlf.search_runs(\n",
    "            experiment_names = [self.experiment_name],\n",
    "            output_format = 'list'\n",
    "        )\n",
    "        runs_name_endtime_pairs = []\n",
    "        for run in runs:\n",
    "            pair = {'run_ID': run.info.run_id, 'end_time': run.info.end_time}\n",
    "            runs_name_endtime_pairs.append(pair)\n",
    "        return runs_name_endtime_pairs\n",
    "\t\n",
    "dataset_analyzer = Dataset_Analyzer(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "mlflow_experiment = MLFlow_Experiment_Runner('random_forest')\n",
    "mlflow_experiment.main(dataset_analyzer.main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea7ea6-3841-43d7-984f-8b7bed339ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
