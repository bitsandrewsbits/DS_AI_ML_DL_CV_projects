{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463bd9f5-1618-40cb-b185-b865419490d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    accuracy_score, ConfusionMatrixDisplay\n",
    ")\n",
    "import mlflow as mlf\n",
    "from mlflow.sklearn import log_model, save_model\n",
    "from mlflow.models import infer_signature\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d35f2-72b4-4059-bacd-4a0eb696580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Analyzer:\n",
    "    def __init__(self, dataset_url: str):\n",
    "        self.CSV_dataset_URL = dataset_url\n",
    "        self.CSV_dataset = self.get_dataset_in_CSV_from_URL(self.CSV_dataset_URL)\n",
    "        self.dataset_column_names = self.get_dataset_columns_names()\n",
    "        self.dataset_columns_types = dict(self.CSV_dataset.dtypes)\n",
    "        self.dataset_columns_with_missing_values = []\n",
    "        self.missing_values_columns_with_int_float_dtypes = []\n",
    "        \n",
    "        self.target_y_columns = ['Survived']\n",
    "        self.excluded_features_X = ['SibSp', 'Parch']\n",
    "        self.features_set_X = pd.DataFrame()\n",
    "        self.target_set_y = pd.DataFrame()\n",
    "        self.train_set_X = pd.DataFrame()\n",
    "        self.train_set_y = np.array\n",
    "        self.test_set_X = pd.DataFrame()\n",
    "        self.test_set_y = np.array\n",
    "        self.target_y_classes_names = ['Not Survived', 'Survived']\n",
    "        self.datasets_for_mlflow = {'train': {}, 'test':{}}\n",
    "    \n",
    "        self.ML_classifiers_model = {'random_forest': RandomForestClassifier} # in the future - maybe I'll add new models\n",
    "        self.selected_model_name_for_experiment = 'random_forest'\n",
    "        self.model_for_experiment = object\n",
    "        self.prediction_of_target_y = []\n",
    "        self.confusion_matrix = []\n",
    "        self.confusion_matrix_figure = object\n",
    "        self.classification_report = {}\n",
    "        self.accuracy = 0.0\n",
    "        self.weighted_average_precision = 0.0\n",
    "        self.weighted_average_recall = 0.0\n",
    "        self.weighted_average_f1_score = 0.0\n",
    "    \n",
    "    def main(self):\n",
    "        self.make_data_preparation_for_training()\n",
    "        print('Training ML model.')\n",
    "        self.init_classifier_model_for_experiment(self.selected_model_name_for_experiment)\n",
    "        self.train_classifier_model()\n",
    "        print('Make prediction of target y values from test set X')\n",
    "        self.make_prediction_on_test_dataset()\n",
    "        print('Model Evaluation:')\n",
    "        self.evaluate_quality_of_ML_model()\n",
    "        self.define_confusion_matrix_figure()\n",
    "    \n",
    "    def make_data_preparation_for_training(self):\n",
    "        self.show_dataset()\n",
    "        self.remove_all_string_type_columns_from_dataset()\n",
    "        self.update_dataset_columns_names()\n",
    "        self.update_dataset_columns_types()\n",
    "        self.define_columns_with_missing_values_from_dataset()\n",
    "        self.define_int_float_dtype_missing_value_columns()\n",
    "        self.replace_columns_NaN_values_with_mean_values()\n",
    "        self.define_features_set_X()\n",
    "        self.define_target_set_y()\n",
    "        self.features_max_abs_normalization()\n",
    "        print('Features set X after max abs normalization:')\n",
    "        self.show_features_set_X()\n",
    "        print('=' * 40)\n",
    "        if self.excluded_features_X != []:\n",
    "            self.features_set_X.drop(\n",
    "                self.excluded_features_X, \n",
    "                axis = 'columns', inplace = True\n",
    "            )\n",
    "        print('=' * 40)\n",
    "        print('Splitting dataset for train and test stages.')\n",
    "        self.split_dataset_into_train_test_parts()\n",
    "        print('=' * 40)\n",
    "        self.train_set_X.index = [i for i in range(self.train_set_X.shape[0])]\n",
    "        self.test_set_X.index = [i for i in range(self.test_set_X.shape[0])]\n",
    "        self.define_mlflow_pandas_datasets()\n",
    "    \n",
    "    def show_dataset(self):\n",
    "        print(self.CSV_dataset)\n",
    "    \n",
    "    def get_dataset_columns_names(self):\n",
    "        return self.CSV_dataset.columns\n",
    "    \n",
    "    def update_dataset_columns_names(self):\n",
    "        self.dataset_column_names = self.get_dataset_columns_names()\n",
    "    \n",
    "    def update_dataset_columns_types(self):\n",
    "        self.dataset_columns_types = dict(self.CSV_dataset.dtypes)\n",
    "    \n",
    "    def show_dataset_columns_types(self):\n",
    "        print(self.dataset_columns_types)\n",
    "    \n",
    "    def show_dataset_columns(self):\n",
    "        print(self.dataset_column_names)\n",
    "    \n",
    "    def get_dataset_in_CSV_from_URL(self, url: str):\n",
    "        return pd.read_csv(url)\n",
    "    \n",
    "    def remove_all_string_type_columns_from_dataset(self):\n",
    "        for dataset_column_name in self.dataset_columns_types:\n",
    "            if self.dataset_columns_types[dataset_column_name] == object:\n",
    "                self.CSV_dataset = self.CSV_dataset.drop(dataset_column_name, axis = 1)\n",
    "        return True\n",
    "    \n",
    "    def define_columns_with_missing_values_from_dataset(self):\n",
    "        missing_values_by_bool_mapping_of_dataset = self.CSV_dataset.isna()\n",
    "    \n",
    "        for dataset_column in self.dataset_column_names:\n",
    "            column_values = missing_values_by_bool_mapping_of_dataset[dataset_column].values\n",
    "            if True in column_values:\n",
    "                self.dataset_columns_with_missing_values.append(dataset_column)\n",
    "                print(f'Missing values column - {dataset_column}!')\n",
    "        return True\n",
    "    \n",
    "    def define_int_float_dtype_missing_value_columns(self):\n",
    "        for missing_value_column in self.dataset_columns_with_missing_values:\n",
    "            if self.dataset_columns_types[missing_value_column] != object:\n",
    "                self.missing_values_columns_with_int_float_dtypes.append(missing_value_column)\n",
    "        return True\n",
    "    \n",
    "    def replace_columns_NaN_values_with_mean_values(self):\n",
    "        for int_float_column in self.missing_values_columns_with_int_float_dtypes:\n",
    "            column_mean_value = self.CSV_dataset[int_float_column].mean(skipna = True)\n",
    "            self.CSV_dataset[int_float_column] = self.CSV_dataset[int_float_column].replace(\n",
    "                to_replace = np.nan, value = column_mean_value\n",
    "            )\n",
    "        return True\n",
    "    \n",
    "    def define_features_set_X(self):\n",
    "        for target_y_column in self.target_y_columns:\n",
    "            self.features_set_X = self.CSV_dataset.drop(target_y_column, axis = 1)\n",
    "        return True\n",
    "    \n",
    "    def show_features_set_X(self):\n",
    "        print(self.features_set_X)\n",
    "    \n",
    "    def define_target_set_y(self):\n",
    "        self.target_set_y = self.CSV_dataset[self.target_y_columns]\n",
    "        return True\n",
    "    \n",
    "    def split_dataset_into_train_test_parts(self):\n",
    "        self.train_set_X, self.test_set_X, \\\n",
    "        self.train_set_y, self.test_set_y = train_test_split(\n",
    "            self.features_set_X, self.target_set_y, test_size = 0.2, random_state = 42\n",
    "            )\n",
    "        self.train_set_y = self.train_set_y.values.reshape(-1)\n",
    "        self.test_set_y = self.test_set_y.values.reshape(-1)\n",
    "        return True\n",
    "    \n",
    "    def features_max_abs_normalization(self):\n",
    "        features_column_names = self.features_set_X.columns\n",
    "        for features_column in features_column_names:\n",
    "            max_abs_column_value = self.features_set_X[features_column].abs().max()\n",
    "            self.features_set_X[features_column] = self.features_set_X[features_column] / max_abs_column_value\n",
    "        return True\n",
    "    \n",
    "    def init_classifier_model_for_experiment(self, model_name: str):\n",
    "        self.model_for_experiment = self.ML_classifiers_model[model_name]()\n",
    "    \n",
    "    def train_classifier_model(self):\n",
    "        self.model_for_experiment.fit(self.train_set_X, self.train_set_y)\n",
    "        \n",
    "    def make_prediction_on_test_dataset(self):\n",
    "        self.prediction_of_target_y = self.model_for_experiment.predict(self.test_set_X)\n",
    "    \n",
    "    def evaluate_quality_of_ML_model(self):\n",
    "        self.define_confusion_matrix()\n",
    "        self.define_classification_report()\n",
    "        self.define_model_accuracy()\n",
    "        self.define_model_weighted_average_precision()\n",
    "        self.define_model_weighted_average_recall()\n",
    "        self.define_model_weighted_average_f1_score()\n",
    "    \n",
    "    def define_confusion_matrix(self):\n",
    "        self.confusion_matrix = confusion_matrix(self.test_set_y, self.prediction_of_target_y)\n",
    "\n",
    "    def define_model_accuracy(self):\n",
    "        self.accuracy = round(\n",
    "            accuracy_score(self.test_set_y, self.prediction_of_target_y),\n",
    "        3)\n",
    "\n",
    "    def define_model_weighted_average_precision(self):\n",
    "        self.weighted_average_precision = round(\n",
    "            self.classification_report[\"weighted avg\"][\"precision\"],\n",
    "        3)\n",
    "\n",
    "    def define_model_weighted_average_recall(self):\n",
    "        self.weighted_average_recall = round(\n",
    "            self.classification_report[\"weighted avg\"][\"recall\"], \n",
    "        3)\n",
    "\n",
    "    def define_model_weighted_average_f1_score(self):\n",
    "        self.weighted_average_f1_score = round(\n",
    "            self.classification_report[\"weighted avg\"][\"f1-score\"], \n",
    "        3)\n",
    "\n",
    "    def define_confusion_matrix_figure(self):\n",
    "        confusion_matrix_display_obj = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = self.confusion_matrix,\n",
    "            display_labels = self.model_for_experiment.classes_\n",
    "        )\n",
    "        self.confusion_matrix_figure = confusion_matrix_display_obj.plot().figure_\n",
    "\n",
    "    def define_classification_report(self):\n",
    "        self.classification_report = classification_report(\n",
    "            self.test_set_y, self.prediction_of_target_y,\n",
    "            target_names = self.target_y_classes_names,\n",
    "            digits = 3,\n",
    "            output_dict = True\n",
    "        )\n",
    "\n",
    "    def define_mlflow_pandas_datasets(self):\n",
    "        train_df_y = self.get_labels_y_as_dataframe(self.train_set_y)\n",
    "        train_df_X_y = pd.concat(\n",
    "            [self.train_set_X, train_df_y], axis = 1\n",
    "        )\n",
    "        test_df_y = self.get_labels_y_as_dataframe(self.test_set_y)\n",
    "        test_df_X_y = pd.concat(\n",
    "            [self.test_set_X, test_df_y], axis = 1\n",
    "        )\n",
    "        self.datasets_for_mlflow[\"train\"] = mlf.data.from_pandas(\n",
    "            train_df_X_y, targets = self.target_y_columns[0]\n",
    "        )\n",
    "        self.datasets_for_mlflow[\"test\"] = mlf.data.from_pandas(\n",
    "            test_df_X_y, targets = self.target_y_columns[0]\n",
    "        )\n",
    "\n",
    "    def get_labels_y_as_dataframe(self, labels: np.array):\n",
    "        return pd.DataFrame(labels, columns = self.target_y_columns)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af610e2c-8bd2-4015-a3f9-0114a066ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook only for testing as API for main classifier program.\n",
    "class MLFlow_Experiment_Runner:\n",
    "    def __init__(self, classifier_model_name: str):\n",
    "        self.classifier_model_name = classifier_model_name\n",
    "        self.experiment_name = self.get_experiment_name()\n",
    "        self.active_experiment = object\n",
    "        self.current_run_name = ''\n",
    "        self.max_experiment_runs = 10\n",
    "        self.tracking_server_IP = os.getenv('MLFLOW_IP')\n",
    "        self.tracking_server_port = 5000\n",
    "        self.tracking_server_URI = f\"http://{self.tracking_server_IP}:{self.tracking_server_port}\"\n",
    "\n",
    "    def main(self, target_classifier_object):\n",
    "        self.set_mlflow_server_URI()\n",
    "        if self.experiment_exist():\n",
    "            print(f'[INFO] Experiment - {self.experiment_name} - active!')\n",
    "            self.set_experiment_as_active()\n",
    "        else:\n",
    "            print(f'[INFO] Experiment - {self.experiment_name} does not exist!')\n",
    "            self.create_new_experiment()\n",
    "        self.delete_old_experiments_runs()\n",
    "        \n",
    "        self.current_run_name = self.get_current_run_name()\n",
    "        self.start_experiment_run(target_classifier_object)\n",
    "        # TODO: think, how to get all logged models and\n",
    "        # how to delete some by criteria\n",
    "\n",
    "    def start_experiment_run(self, classifier_object):\n",
    "        with mlf.start_run(run_name = self.current_run_name):\n",
    "            print(\"[INFO] Start classifier experiment...\")\n",
    "            mlf.sklearn.autolog(disable = True)\n",
    "            classifier_object.main()\n",
    "            mlf.log_metric('accuracy', classifier_object.accuracy)\n",
    "            mlf.log_metric('precision', classifier_object.weighted_average_precision)\n",
    "            mlf.log_metric('recall', classifier_object.weighted_average_recall)\n",
    "            mlf.log_metric('f1-score', classifier_object.weighted_average_f1_score)\n",
    "            mlf.log_figure(\n",
    "                classifier_object.confusion_matrix_figure,\n",
    "                artifact_file = 'confusion_matrix.png'\n",
    "            )\n",
    "            mlf.log_dict(\n",
    "                dictionary = classifier_object.classification_report,\n",
    "                artifact_file = 'classification_report.json'\n",
    "            )\n",
    "            model_signature = self.get_model_signature(\n",
    "                classifier_object.train_set_X,\n",
    "                classifier_object.test_set_y\n",
    "            )\n",
    "            log_model(\n",
    "                sk_model = classifier_object.model_for_experiment,\n",
    "                name = self.classifier_model_name,\n",
    "                signature = model_signature\n",
    "            )\n",
    "            mlf.log_input(\n",
    "                classifier_object.datasets_for_mlflow[\"train\"],\n",
    "                context = \"training\"\n",
    "            )\n",
    "            mlf.log_input(\n",
    "                classifier_object.datasets_for_mlflow[\"test\"],\n",
    "                context = \"testing\"\n",
    "            )\n",
    "            save_model(\n",
    "                sk_model = classifier_object.model_for_experiment,\n",
    "                path = self.get_dirname_for_model_saving(classifier_object)\n",
    "            )\n",
    "    \n",
    "    def delete_old_experiments_runs(self):\n",
    "        runs_name_endtime_pairs = self.get_experiment_runs_name_endtime_pairs()\n",
    "        runs_name_endtime_pairs.sort(key = lambda run: run['end_time'])\n",
    "        if self.experiment_exceed_max_runs(runs_name_endtime_pairs):\n",
    "            print(f\"[INFO] Experiment has more than {self.max_experiment_runs} runs. Deleting old runs...\")\n",
    "            self.delete_old_time_experiment_runs(runs_name_endtime_pairs)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def set_mlflow_server_URI(self):\n",
    "        print('[INFO] Setting Tracking Server URI...')\n",
    "        mlf.set_tracking_uri(self.tracking_server_URI)\n",
    "    \n",
    "    def get_experiment_name(self):\n",
    "        return f\"{self.classifier_model_name}_classifier\"\n",
    "    \n",
    "    def experiment_exist(self):\n",
    "        if mlf.get_experiment_by_name(self.experiment_name):\n",
    "            print(f'[INFO] Experiment {self.experiment_name} already exist!')\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def create_new_experiment(self):\n",
    "        print(f'[INFO] Creating experiment - {self.experiment_name}...')\n",
    "        mlf.create_experiment(self.experiment_name)\n",
    "    \n",
    "    def set_experiment_as_active(self):\n",
    "        return mlf.set_experiment(self.experiment_name)\n",
    "\n",
    "    def get_current_run_name(self):\n",
    "        runs = self.get_experiment_runs_name_endtime_pairs()\n",
    "        current_run_number = len(runs) + 1\n",
    "        return f\"train_test_{current_run_number}\"\n",
    "\n",
    "    def delete_old_time_experiment_runs(self, runs: list):\n",
    "        target_runs_for_deleting = self.get_target_runs_for_deleting(runs)\n",
    "        for run in target_runs_for_deleting:\n",
    "            run_ID = run['run_ID']\n",
    "            mlf.delete_run(run_ID)\n",
    "            print(f\"[INFO] Deleted Run with ID: {run_ID}\")\n",
    "        return True\n",
    "\n",
    "    def get_target_runs_for_deleting(self, sorted_runs_by_time: list):\n",
    "        return sorted_runs_by_time[:self.max_experiment_runs]\n",
    "    \n",
    "    def experiment_exceed_max_runs(self, runs: list):\n",
    "        runs_amount = len(runs)\n",
    "        if runs_amount <= self.max_experiment_runs:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "            \n",
    "    def get_experiment_runs_name_endtime_pairs(self) -> list[dict]:\n",
    "        runs = mlf.search_runs(\n",
    "            experiment_names = [self.experiment_name],\n",
    "            output_format = 'list'\n",
    "        )\n",
    "        runs_name_endtime_pairs = []\n",
    "        for run in runs:\n",
    "            pair = {'run_ID': run.info.run_id, 'end_time': run.info.end_time}\n",
    "            runs_name_endtime_pairs.append(pair)\n",
    "        return runs_name_endtime_pairs\n",
    "\n",
    "    def get_model_signature(self, input_dataset: pd.DataFrame, prediction):\n",
    "        return infer_signature(\n",
    "            model_input = input_dataset,\n",
    "            model_output = prediction\n",
    "        )\n",
    "\n",
    "    def get_dirname_for_model_saving(self, classifier_obj):\n",
    "        model_dirname = \"trained_models/\"\n",
    "        model_dirname += f\"{classifier_obj.selected_model_name_for_experiment}\"\n",
    "        model_dirname += f\"_{self.current_run_name}\"\n",
    "        return model_dirname\n",
    "        \n",
    "dataset_analyzer = Dataset_Analyzer(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "mlflow_experiment = MLFlow_Experiment_Runner('random_forest')\n",
    "mlflow_experiment.main(dataset_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629158e-6cd9-4544-b4e7-eb2b89ac4264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
