{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing for DistilBERT FineTuning**"
      ],
      "metadata": {
        "id": "2DAoYpEtHvJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connect to Google Drive disk**"
      ],
      "metadata": {
        "id": "lJFeKuYgIIOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if 'drive' in os.listdir('.'):\n",
        "  print('Google Drive disk already mounted!')\n",
        "else:\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rGQUNHZkOaFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialize Global Variables**"
      ],
      "metadata": {
        "id": "lKiBFYPtIUc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Google_Drive_checkpoints_dir_path = '/content/drive/MyDrive/DistilBERT_finetuning_checkpoints'\n",
        "fine_tuning_Colab_dir = \"/content/fine_tuned_DistilBERT\"\n",
        "saved_train_eval_metrics_filename = \"DistilBERT_train_eval_metrics.csv\"\n",
        "fine_tune_checkpoints_GDrive_dir = 'DistilBERT_finetuning_checkpoints'\n",
        "DistilBERT_prepared_datasets_GDrive_dir = 'DistilBERT_prepared_datasets'\n",
        "downloaded_datasets_Colab_dirname = 'data'\n",
        "pre_trained_evals_reports_file = 'pre-trained_model_evaluations.json'"
      ],
      "metadata": {
        "id": "jjiI3IZ0SpbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading Dataset**"
      ],
      "metadata": {
        "id": "nFkU-pb_IbwH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssdhk1sx9cpS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "if DistilBERT_prepared_datasets_GDrive_dir in os.listdir('/content/drive/MyDrive/'):\n",
        "  print('Train-Validation-Test dataset already exist and prepared on Google Drive disk!')\n",
        "  print('Copying datasets from GDrive to local dir...')\n",
        "  os.system(f\"cp -r /content/drive/MyDrive/{DistilBERT_prepared_datasets_GDrive_dir}/* .\")\n",
        "elif downloaded_datasets_Colab_dirname in os.listdir('.'):\n",
        "  print('Dataset already downloaded to Colab.')\n",
        "else:\n",
        "  print(\"Datasets don't exist on GDrive disk. Downloading...\")\n",
        "  !mkdir data\n",
        "  !cd data\n",
        "  # download Large Movie Review Dataset as archive:\n",
        "  !curl --output large_movie_review_dataset.tar.gz https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "  # unzip dataset:\n",
        "  !gzip -d large_movie_review_dataset.tar.gz\n",
        "  !tar -xf large_movie_review_dataset.tar\n",
        "  # move files from aclImdb dir -> just data:\n",
        "  !mv aclImdb/* data/\n",
        "  # remove empty aclImdb dir:\n",
        "  !rm -r aclImdb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create temp virtual environment**"
      ],
      "metadata": {
        "id": "oZOTdOvIIrEc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tsJ6ig-njwhl"
      },
      "outputs": [],
      "source": [
        "# VENV Creating\n",
        "if 'temp_venv' in os.listdir('.'):\n",
        "  print('Virtual env already created.')\n",
        "else:\n",
        "  print('Creating temp venv...')\n",
        "  !pip3 install virtualenv\n",
        "  !virtualenv temp_venv\n",
        "  !source temp_venv/bin/activate\n",
        "  !pip install numpy==1.26\n",
        "  !pip install evaluate\n",
        "  !pip install emoji\n",
        "  !pip install numba"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import necessary libs**"
      ],
      "metadata": {
        "id": "DzLrkzPbI0CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import DistilBERT_FineTuning_dataset_creation as ft_ds\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import additional_functions_for_data_preprocessing as ad_fncs\n",
        "from datasets import DatasetDict, Dataset\n",
        "from numba import cuda\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import TrainerCallback\n",
        "from transformers import create_optimizer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import json"
      ],
      "metadata": {
        "id": "ukLHuc2LPg2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-Validation-Test Datasets Creation with Neutral Reviews Oversampling**"
      ],
      "metadata": {
        "id": "LSGaHg7CAzdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12oBG2S-ACpw"
      },
      "outputs": [],
      "source": [
        "datasets_files_info = {\n",
        "    \"train\": {\n",
        "        \"positive_reviews_path\": 'data/train/pos',\n",
        "        \"negative_reviews_path\": 'data/train/neg'\n",
        "    },\n",
        "    \"test\": {\n",
        "        \"positive_reviews_path\": 'data/test/pos',\n",
        "        \"negative_reviews_path\": 'data/test/neg'\n",
        "    }\n",
        "}\n",
        "\n",
        "datasets_save_path = \".\"\n",
        "class_samples_amount = 8000  # by default - entire dataset - just delete this var from main calling.\n",
        "\n",
        "def main(datasets_files: dict, save_path: str, class_samples_amount = 'all', oversample_neutral_reviews = True):\n",
        "    datasets = get_datasets_from_reviews_files(datasets_files, class_samples_amount)\n",
        "    target_dataset_for_split = get_merged_train_test_datasets_into_one(datasets)\n",
        "    dataset_with_neutral_reviews = include_neutral_reviews_to_result_dataset(\n",
        "        target_dataset_for_split\n",
        "    )\n",
        "    train_val_test_datasets = get_train_validation_test_datasets(\n",
        "        dataset_with_neutral_reviews\n",
        "    )\n",
        "    if oversample_neutral_reviews:\n",
        "      neutral_reviews_distribution_in_datasets = get_neutral_reviews_distribution_in_datasets(\n",
        "          train_val_test_datasets\n",
        "      )\n",
        "      neutral_reviews_oversampling_coeffs = get_neutral_reviews_oversampling_coeffs_for_datasets(\n",
        "          train_val_test_datasets, neutral_reviews_distribution_in_datasets\n",
        "      )\n",
        "      neutral_reviews_oversampled_datasets = get_neutral_reviews_oversampled_datasets(\n",
        "          train_val_test_datasets,\n",
        "          neutral_reviews_distribution_in_datasets,\n",
        "          neutral_reviews_oversampling_coeffs\n",
        "      )\n",
        "      converted_train_val_test_datasets = get_converted_datasets_into_DatasetDict_Dataset(\n",
        "        neutral_reviews_oversampled_datasets\n",
        "      )\n",
        "    save_train_val_test_datasets_to_disk(\n",
        "        converted_train_val_test_datasets, save_path\n",
        "    )\n",
        "\n",
        "def save_train_val_test_datasets_to_disk(datasets: DatasetDict, save_path: str):\n",
        "    datasets.save_to_disk(\n",
        "        dataset_dict_path = save_path,\n",
        "        storage_options = {}\n",
        "    )\n",
        "    print('Train, Validation, Test datasets saved.')\n",
        "\n",
        "def get_train_validation_test_datasets(target_dataset: pd.DataFrame):\n",
        "    train_dataset_for_split, test_dataset = train_test_split(\n",
        "        target_dataset, test_size = 0.1, shuffle = True\n",
        "    )\n",
        "    train_dataset, validation_dataset = train_test_split(\n",
        "        train_dataset_for_split, train_size = 0.92, shuffle = True\n",
        "    )\n",
        "    return {\n",
        "        \"train\": train_dataset,\n",
        "        \"validation\": validation_dataset,\n",
        "        \"test\": test_dataset\n",
        "    }\n",
        "\n",
        "def get_converted_datasets_into_DatasetDict_Dataset(datasets: dict[pd.DataFrame]):\n",
        "    for dataset in datasets:\n",
        "        datasets[dataset] = Dataset.from_pandas(\n",
        "            datasets[dataset], preserve_index = False\n",
        "        )\n",
        "    return DatasetDict(datasets)\n",
        "\n",
        "def get_datasets_from_reviews_files(\n",
        "datasets_files_info: dict, class_samples_amount) -> dict[pd.DataFrame]:\n",
        "    if class_samples_amount != 'all':\n",
        "        class_samples_amount_per_dataset_type = class_samples_amount // 2\n",
        "    else:\n",
        "        class_samples_amount_per_dataset_type = class_samples_amount\n",
        "    result_datasets = {}\n",
        "    for dataset_type in datasets_files_info:\n",
        "        dataset_creation = ft_ds.DistilBERT_Fune_Tuning_Dataset_Creation(\n",
        "            datasets_files_info[dataset_type][\"positive_reviews_path\"],\n",
        "            datasets_files_info[dataset_type][\"negative_reviews_path\"]\n",
        "        )\n",
        "        result_datasets[dataset_type] = dataset_creation.main(class_samples_amount_per_dataset_type)\n",
        "    return result_datasets\n",
        "\n",
        "def get_merged_train_test_datasets_into_one(\n",
        "train_test_datasets: dict[pd.DataFrame]) -> pd.DataFrame:\n",
        "    target_dataset_for_splitting = pd.concat(\n",
        "        [train_test_datasets[\"train\"], train_test_datasets[\"test\"]],\n",
        "        axis = 0, ignore_index = True\n",
        "    )\n",
        "    return target_dataset_for_splitting\n",
        "\n",
        "def include_neutral_reviews_to_result_dataset(res_dataset: pd.DataFrame):\n",
        "    neutral_reviews_df = pd.read_json(\n",
        "        \"neutral_reviews.json\", orient = 'records', lines = True\n",
        "    )\n",
        "    neutral_reviews_df['label'] = 2\n",
        "    reviews_3_types_dataset = pd.concat(\n",
        "        [res_dataset, neutral_reviews_df],\n",
        "        axis = 0, ignore_index = True\n",
        "    )\n",
        "    return reviews_3_types_dataset\n",
        "\n",
        "def get_neutral_reviews_oversampled_datasets(datasets: dict[pd.DataFrame],\n",
        "neutral_reviews_distribution: dict, neutral_reviews_oversampling_coeffs: dict) -> pd.DataFrame:\n",
        "  for dataset_type in datasets:\n",
        "    current_dataset = datasets[dataset_type]\n",
        "    for _ in range(neutral_reviews_oversampling_coeffs[dataset_type] - 1):\n",
        "      current_dataset = pd.concat(\n",
        "        [\n",
        "          current_dataset,\n",
        "          neutral_reviews_distribution[dataset_type]\n",
        "        ],\n",
        "        ignore_index = True\n",
        "      )\n",
        "    datasets[dataset_type] = current_dataset\n",
        "  return datasets\n",
        "\n",
        "def get_oversampling_coefficient(real_reviews_amount: int, target_reviews_amount: int):\n",
        "    oversampling_coeff = target_reviews_amount // real_reviews_amount\n",
        "    return oversampling_coeff\n",
        "\n",
        "def get_neutral_reviews_oversampling_coeffs_for_datasets(datasets: dict[pd.DataFrame], neutral_reviews_distribution: dict):\n",
        "  neutral_reviews_oversampling_coeffs = {}\n",
        "  for dataset_type in datasets:\n",
        "    positive_reviews = datasets[dataset_type][datasets[dataset_type]['label'] == 1]\n",
        "    neutral_reviews_oversampling_coeffs[dataset_type] = get_oversampling_coefficient(\n",
        "        neutral_reviews_distribution[dataset_type].shape[0], positive_reviews.shape[0]\n",
        "    )\n",
        "  return neutral_reviews_oversampling_coeffs\n",
        "\n",
        "def get_neutral_reviews_distribution_in_datasets(datasets: dict[pd.DataFrame]):\n",
        "  datasets_neutral_reviews_distrition = {}\n",
        "  for dataset_type in datasets:\n",
        "    datasets_neutral_reviews_distrition[dataset_type] = get_reviews_from_df_by_label(\n",
        "        datasets[dataset_type], 2\n",
        "    )\n",
        "  return datasets_neutral_reviews_distrition\n",
        "\n",
        "def get_reviews_from_df_by_label(dataset: pd.DataFrame, label: int) -> pd.DataFrame:\n",
        "  return dataset[dataset['label'] == label]\n",
        "\n",
        "if 'train' in os.listdir('.'):\n",
        "  print('Prepared datasets already loaded/created.')\n",
        "else:\n",
        "  print('Creating prepared train-validation-test datasets.')\n",
        "  main(datasets_files_info, datasets_save_path, class_samples_amount)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checkpoints and Prepared Datasets Dirs Creation**"
      ],
      "metadata": {
        "id": "AdxMF7p0-aps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if fine_tune_checkpoints_GDrive_dir not in os.listdir('/content/drive/MyDrive/'):\n",
        "  os.mkdir(f'/content/drive/MyDrive/{fine_tune_checkpoints_GDrive_dir}')\n",
        "  print('Dir for DistilBERT fine-tuning checkpoints created on your Google Drive.')\n",
        "else:\n",
        "  print('Dir for DistilBERT fine-tuning checkpoints already exists.')\n",
        "\n",
        "if DistilBERT_prepared_datasets_GDrive_dir not in os.listdir('/content/drive/MyDrive/'):\n",
        "  print('Creating dir for DistilBERT prepared datasets on your Google Drive.')\n",
        "  os.mkdir(f'/content/drive/MyDrive/{DistilBERT_prepared_datasets_GDrive_dir}')\n",
        "else:\n",
        "  print('Dir for DistilBERT prepared datasets already exists.')"
      ],
      "metadata": {
        "id": "owumV84uQpV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepared Datasets Uploading to Google Disk**"
      ],
      "metadata": {
        "id": "B3pNZFm9-vhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'train' in os.listdir(f\"/content/drive/MyDrive/{DistilBERT_prepared_datasets_GDrive_dir}\"):\n",
        "  print('Prepared datasets already uploaded to GDrive disk.')\n",
        "else:\n",
        "  print('Uploading to your Google Drive disk prepared datasets...')\n",
        "  os.system(f\"cp -r train /content/drive/MyDrive/{DistilBERT_prepared_datasets_GDrive_dir}\")\n",
        "  os.system(f\"cp -r validation /content/drive/MyDrive/{DistilBERT_prepared_datasets_GDrive_dir}\")\n",
        "  os.system(f\"cp -r test /content/drive/MyDrive/{DistilBERT_prepared_datasets_GDrive_dir}\")\n",
        "  os.system(f\"cp dataset_dict.json /content/drive/MyDrive/{DistilBERT_prepared_datasets_GDrive_dir}\")"
      ],
      "metadata": {
        "id": "hmCV5A0yPlpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPU Memory Releasing(optional)**"
      ],
      "metadata": {
        "id": "WMcfXj6y_VZ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vwxhcm1TAE7t"
      },
      "outputs": [],
      "source": [
        "# optional\n",
        "GPU_memory_allocated = torch.cuda.memory_allocated()\n",
        "GPU_memory_reserved = torch.cuda.memory_reserved()\n",
        "print(f'GPU allocated: {GPU_memory_allocated}')\n",
        "print(f'GPU reserved: {GPU_memory_reserved}')\n",
        "# using numba lib\n",
        "GPU_device = cuda.get_current_device()\n",
        "GPU_device.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-Trained DistilBERT Evaluations before FineTuning(baseline metrics - accuracy, precision, recall, F1-score)**"
      ],
      "metadata": {
        "id": "7FbfN3ZB_9pJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"distilbert/distilbert-base-uncased\"\n",
        "\n",
        "ID_to_label = {0: \"negative\", 1: \"positive\", 2: \"neutral\"}\n",
        "label_to_ID = {\"negative\": 0, \"positive\": 1, \"neutral\": 2}\n",
        "datasets_parent_dir = \"\"\n",
        "\n",
        "def main(model_ID, id_to_label, label_to_id):\n",
        "    train_val_test_datasets = load_train_val_test_datasets(datasets_parent_dir)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    tokenized_datasets = train_val_test_datasets.map(\n",
        "        lambda dataset: tokenizer(dataset[\"text\"], truncation = True),\n",
        "        batched = True\n",
        "    )\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "\n",
        "    distilbert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_ID, num_labels = 3,\n",
        "        id2label = id_to_label, label2id = label_to_id,\n",
        "    )\n",
        "\n",
        "    eval_args = TrainingArguments(\n",
        "        report_to = \"tensorboard\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model = distilbert_model,\n",
        "        args = eval_args,\n",
        "        processing_class = tokenizer,\n",
        "        data_collator = data_collator\n",
        "    )\n",
        "    print('Pre-trained Model predictions on test dataset before FT...')\n",
        "    model_evaluations = []\n",
        "    for i in range(1, 3):\n",
        "      model_prediction = trainer.predict(\n",
        "            test_dataset = tokenized_datasets[\"test\"]\n",
        "      )\n",
        "      model_prediction_labels = get_prediction_labels(model_prediction.predictions)\n",
        "      current_evaluation = classification_report(\n",
        "          y_true = model_prediction.label_ids,\n",
        "          y_pred = model_prediction_labels,\n",
        "          labels = [0, 1, 2],\n",
        "          target_names = [\"negative\", \"positive\", \"neutral\"],\n",
        "          output_dict = True\n",
        "      )\n",
        "      model_evaluations.append(current_evaluation)\n",
        "\n",
        "    save_pretrained_model_evaluations(model_evaluations)\n",
        "\n",
        "def save_pretrained_model_evaluations(model_evals_reports: list):\n",
        "  with open(pre_trained_evals_reports_file, 'w') as evals_f:\n",
        "      json.dump(model_evals_reports, evals_f, indent = 4)\n",
        "\n",
        "def load_train_val_test_datasets(datasets_parent_dir_path: str) -> DatasetDict:\n",
        "    loaded_datasets = DatasetDict.load_from_disk(\n",
        "        dataset_dict_path = datasets_parent_dir_path\n",
        "    )\n",
        "    return loaded_datasets\n",
        "\n",
        "def get_prediction_labels(predict_classes_probabilities: np.array):\n",
        "  predict_labels = []\n",
        "  for test_sample_probabilities in predict_classes_probabilities:\n",
        "    predict_label = list(test_sample_probabilities).index(max(test_sample_probabilities))\n",
        "    predict_labels.append(predict_label)\n",
        "  return predict_labels\n",
        "\n",
        "# TODO: think, how to save pre-trained model evaluation results for further\n",
        "# analysis and after FT comparison.\n",
        "main(model_id, ID_to_label, label_to_ID)"
      ],
      "metadata": {
        "id": "5pILg8zjICCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT5hD7BHKgRJ"
      },
      "outputs": [],
      "source": [
        "# DistilBERT model fine-tuning\n",
        "datasets_parent_dir = \"\" # only for Colab env\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "total_train_epochs_amount = 30\n",
        "batch_size = 85  # max for GPU T4 = 15GB\n",
        "\n",
        "session_remained_free_hours_runtime = 1  # ! Check your current free runtime hours! Then - 1 - just in case.\n",
        "trainer_estimated_1_train_epoch_time_in_min = 15 # change after first test epoch!\n",
        "possible_train_epochs_by_your_runtime_hours = (session_remained_free_hours_runtime * 60) // trainer_estimated_1_train_epoch_time_in_min\n",
        "\n",
        "train_eval_metrics = {\"train_loss\": [], \"validation_loss\": [], \"validation_accuracy\": []}\n",
        "do_finally_prediction_on_test_dataset = False\n",
        "\n",
        "class ColabMaxTrainEpochsCallback(TrainerCallback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.completed_train_epochs = 0\n",
        "\n",
        "  def on_evaluate(self, args, state, control, **kwargs):\n",
        "    self.completed_train_epochs += 1\n",
        "    if self.completed_train_epochs == possible_train_epochs_by_your_runtime_hours:\n",
        "      control.should_training_stop = True\n",
        "    elif state.epoch == total_train_epochs_amount:\n",
        "      do_finally_prediction_on_test_dataset = True\n",
        "    train_eval_metrics[\"train_loss\"].append(state.log_history[-2]['loss'])\n",
        "    train_eval_metrics[\"validation_loss\"].append(state.log_history[-1]['eval_loss'])\n",
        "    train_eval_metrics[\"validation_accuracy\"].append(state.log_history[-1]['eval_accuracy'])\n",
        "\n",
        "def main():\n",
        "    train_val_test_datasets = load_train_val_test_datasets(datasets_parent_dir)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    tokenized_datasets = train_val_test_datasets.map(\n",
        "        lambda dataset: tokenizer(dataset[\"text\"], truncation = True),\n",
        "        batched = True\n",
        "    )\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "\n",
        "    distilbert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_id, num_labels = 3,\n",
        "        id2label = ID_to_label, label2id = label_to_ID,\n",
        "    )\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir = fine_tuning_Colab_dir,\n",
        "        learning_rate = 2e-5,\n",
        "        per_device_train_batch_size = batch_size, #-|\n",
        "        per_device_eval_batch_size = batch_size,  #-|\n",
        "        # 30 mins/epoch(always test 1 epoch to know how much time it takes)\n",
        "        num_train_epochs = total_train_epochs_amount,\n",
        "        weight_decay = 0.01,\n",
        "        eval_strategy = \"epoch\",\n",
        "        logging_strategy = 'epoch',\n",
        "        save_strategy = \"epoch\",\n",
        "        logging_steps = 1,\n",
        "        load_best_model_at_end = True,\n",
        "        save_total_limit = 2,\n",
        "        report_to = \"tensorboard\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model = distilbert_model,\n",
        "        args = training_args,\n",
        "        train_dataset = tokenized_datasets[\"train\"],\n",
        "        eval_dataset = tokenized_datasets[\"validation\"],\n",
        "        processing_class = tokenizer,\n",
        "        data_collator = data_collator,\n",
        "        compute_metrics = compute_accuracy_metric,\n",
        "        callbacks = [ColabMaxTrainEpochsCallback]\n",
        "    )\n",
        "\n",
        "    print(f'Float part of total training: {possible_train_epochs_by_your_runtime_hours}')\n",
        "    if os.listdir(Google_Drive_checkpoints_dir_path) != []:\n",
        "      os.system(f\"cp -r {Google_Drive_checkpoints_dir_path}/* {fine_tuning_Colab_dir}\")\n",
        "      print('[INFO] Continue training from saved checkpoint...')\n",
        "      trainer.train(resume_from_checkpoint = True)\n",
        "    else:\n",
        "      trainer.train()\n",
        "    train_eval_metrics_df = pd.DataFrame(train_eval_metrics)\n",
        "    print(train_eval_metrics_df)\n",
        "\n",
        "    if saved_train_eval_metrics_filename in os.listdir(\"/content/drive/MyDrive/\"):\n",
        "      saved_train_eval_metrics_df = pd.read_csv(f\"/content/drive/MyDrive/{saved_train_eval_metrics_filename}\")\n",
        "      print('Saved Train-eval metrics Dataset:')\n",
        "      print(saved_train_eval_metrics_df)\n",
        "      updated_train_eval_metrics_df = pd.concat([saved_train_eval_metrics_df, train_eval_metrics_df], ignore_index = True)\n",
        "      updated_train_eval_metrics_df.to_csv(f\"/content/drive/MyDrive/{saved_train_eval_metrics_filename}\", index = False)\n",
        "      print(\"Updated Train-eval metrics Dataset:\")\n",
        "      print(updated_train_eval_metrics_df)\n",
        "    else:\n",
        "      train_eval_metrics_df.to_csv(f\"/content/drive/MyDrive/{saved_train_eval_metrics_filename}\", index = False)\n",
        "\n",
        "    os.system(f\"rm -r {Google_Drive_checkpoints_dir_path}/*\")\n",
        "    os.system(f\"cp -r {fine_tuning_Colab_dir}/checkpoint-* {Google_Drive_checkpoints_dir_path}\")\n",
        "\n",
        "    if do_finally_prediction_on_test_dataset:\n",
        "      model_prediction = trainer.predict(\n",
        "          test_dataset = tokenized_datasets[\"test\"]\n",
        "      )\n",
        "      model_prediction_labels = get_prediction_labels(model_prediction.predictions)\n",
        "      print(\"model prediction labels:\", model_prediction_labels)\n",
        "      print(\"true labels:\", model_prediction.label_ids)\n",
        "      print(classification_report(\n",
        "          y_true = model_prediction.label_ids,\n",
        "          y_pred = model_prediction_labels,\n",
        "          labels = [0, 1, 2],\n",
        "          target_names = [\"negative\", \"positive\", \"neutral\"]\n",
        "      ))\n",
        "\n",
        "def get_prediction_labels(predict_classes_probabilities: np.array):\n",
        "  predict_labels = []\n",
        "  for test_sample_probabilities in predict_classes_probabilities:\n",
        "    predict_label = list(test_sample_probabilities).index(max(test_sample_probabilities))\n",
        "    predict_labels.append(predict_label)\n",
        "  return predict_labels\n",
        "\n",
        "def load_train_val_test_datasets(datasets_parent_dir_path: str) -> DatasetDict:\n",
        "    loaded_datasets = DatasetDict.load_from_disk(\n",
        "        dataset_dict_path = datasets_parent_dir_path\n",
        "    )\n",
        "    return loaded_datasets\n",
        "\n",
        "def compute_accuracy_metric(evaluated_prediction):\n",
        "    predictions, labels = evaluated_prediction\n",
        "    predictions = np.argmax(predictions, axis = 1)\n",
        "    return accuracy.compute(predictions = predictions, references = labels)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_train_eval_metrics = pd.read_csv(\"/content/drive/MyDrive/DistilBERT_train_eval_metrics.csv\")\n",
        "print(final_train_eval_metrics)"
      ],
      "metadata": {
        "id": "lQqlItrPmTdd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aBeacDyMIPk"
      },
      "outputs": [],
      "source": [
        "# plot train/test losses per epochs\n",
        "train_loss = final_train_eval_metrics[\"train_loss\"]\n",
        "validation_loss = final_train_eval_metrics[\"validation_loss\"]\n",
        "epochs = [i for i in range(1, len(train_loss) + 1)]\n",
        "\n",
        "plt.title(\"Train/Test Loss\")\n",
        "plt.plot(epochs, train_loss, label = \"train_loss\")\n",
        "plt.plot(epochs, validation_loss, label = \"validation_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GReduKFXyMs6"
      },
      "outputs": [],
      "source": [
        "# delete from your Google Drive saved checkpoints(if your want start fine-tuning process from scratch)\n",
        "os.system(f\"rm -r {Google_Drive_checkpoints_dir_path}/*\")\n",
        "# delete saved train-eval metrics on G-Drive\n",
        "!rm /content/drive/MyDrive/DistilBERT_train_eval_metrics.csv\n",
        "!rm -r fine_tuned_DistilBERT/*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}