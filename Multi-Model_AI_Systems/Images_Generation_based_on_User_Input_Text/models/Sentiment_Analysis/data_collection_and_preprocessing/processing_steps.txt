Steps for loading, processing data for Sentiment Analysis model (DistilBERT):
#0) mkdir data
#1) switch dir to data:
cd data

#2) download Large Movie Review Dataset as archive:
curl --output large_movie_review_dataset.tar.gz https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz

#3) unzip dataset:
gzip -d large_movie_review_dataset.tar.gz
tar -xf large_movie_review_dataset.tar

# Total words in Review Dataset vocabulary: 89526 -> columns amount = 89526 + rating column)
# Train/Test splits: 25000 reviews -> rows amount = 25000
# matrix(train/test) - (89527 x 25000)

#4) move files from aclImdb dir -> just data:
mv aclImdb/* data/
#5) remove empty aclImdb dir:
rm -r aclImdb

# ===For COLAB venv! === #
# Upload two files - additional_functions_for_data_preprocessing.py, DistilBERT_FineTuning_dataset_creation.py
# ====================== #
#6) install some libs(If you executing on your local compute, activate venv from previous SD fine-tuning step):
pip install evaluate

# install Zembra SDK:
# (pwd - data_collection_and_preprocessing)
# 1) mkdir neutral_reviews_via_Zembra_API
# 2) cd neutral_reviews_via_Zembra_API
# 3) wget https://cdn.sdks.zembratech.com/zembra-sdk-python.zip
# 4) unzip zembra-sdk-python.zip
# 5) pip install -r python/requirements.txt
# 6) mv python/openapi_client .
# 7) rm neutral_reviews_via_Zembra_API/zembra-sdk-python.zip
# 8) rm -r neutral_reviews_via_Zembra_API/python/
