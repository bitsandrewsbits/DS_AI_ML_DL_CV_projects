In this file I will write every step for data downloading, processing. Maybe it's will be useful for auto-deployment.

IMPORTANT:As we will use pre-trained Text-to-Image model, we use only test2017 dataset and annotations for
Stable Diffusion model fine-tuning.

pwd - ../data

#1)Create 2 dirs - test2017/images, test2017/annotations

#2)install axel util for downloading files.
sudo apt install axel

#3)download files via axel(2 files - test2017.zip, image_info_test2017.zip):
axel -o test2017/test2017.zip http://images.cocodataset.org/zips/test2017.zip
axel -o test2017/test_annotation2017.zip http://images.cocodataset.org/annotations/image_info_test2017.zip

#4) unzip files with respect to their dirs:
unzip -q test2017/test2017.zip -d test2017/images
unzip -q test2017/test_annotation2017.zip -d test2017/annotations

#5) remove image_info_test-dev2017.json from annotations:
rm test2017/annotations/image_info_test-dev2017.json

# Create project VENV(pwd - ../data) and libs for cocoAPI:
1)cd to project root dir: cd ../../../../
2)#1)create Project venv in project root dir - images_gen-tion_user_input-env:
  python3 -m venv "images_gen-tion_user_input-env"
  #2)activate venv: source images_gen-tion_user_input-env/bin/activate
  #3)pip install numpy==1.26(!)
  #4)pip install scikit-image
  #5)pip install matplotlib

# Installing COCO PythonAPI:
1)cd to project COCO API path - ../data_collection_and_preprocessing
2)pip3 install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI
3)cp -r /home/kov_andrew/.local/lib/python3.10/site-packages/pycocotools .
